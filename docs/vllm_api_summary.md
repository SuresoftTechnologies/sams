# vLLM API λ¬Έμ„ μ”μ•½

## π“ μ„λ²„ μ •λ³΄

- **Base URL**: `http://10.10.10.200:19751/v1`
- **λ¨λΈ**: `deepseek-ai/DeepSeek-OCR`
- **API νƒ€μ…**: OpenAI νΈν™ API

---

## π”§ κΈ°λ³Έ μ—”λ“ν¬μΈνΈ

### μƒνƒ ν™•μΈ

| λ©”μ„λ“ | μ—”λ“ν¬μΈνΈ | μ„¤λ… |
|--------|-----------|------|
| `GET` | `/health` | μ„λ²„ μƒνƒ ν™•μΈ |
| `GET` | `/load` | μ„λ²„ λ¶€ν• λ©”νΈλ¦­ μ΅°ν |
| `GET` | `/ping` | ν•‘ μ²΄ν¬ (SageMakerμ©) |
| `POST` | `/ping` | ν•‘ μ²΄ν¬ (SageMakerμ©) |
| `GET` | `/version` | vLLM λ²„μ „ μ •λ³΄ |

---

## π¤– λ¨λΈ κ΄€λ ¨ API

### GET /v1/models
μ‚¬μ© κ°€λ¥ν• λ¨λΈ λ©λ΅ μ΅°ν

**μ‘λ‹µ μμ‹**:
```json
{
  "data": [
    {
      "id": "deepseek-ai/DeepSeek-OCR",
      "object": "model",
      ...
    }
  ]
}
```

---

## π’¬ μ£Όμ” μ¶”λ΅  API

### 1. POST /v1/chat/completions
μ±„ν… μ™„μ„± μƒμ„± (OpenAI ChatGPT API νΈν™)

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "model": "deepseek-ai/DeepSeek-OCR",
  "messages": [
    {
      "role": "system",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "Hello!"
    }
  ],
  "temperature": 0.7,
  "top_p": 1.0,
  "max_tokens": 1000,
  "stream": false
}
```

**μ£Όμ” νλΌλ―Έν„°**:
- `messages`: λ€ν™” λ©”μ‹μ§€ λ°°μ—΄
  - `role`: `developer`, `system`, `user`, `assistant`
  - `content`: λ©”μ‹μ§€ λ‚΄μ©
- `temperature`: μƒν”λ§ μ¨λ„ (0.0 ~ 2.0)
- `top_p`: nucleus sampling
- `max_tokens`: μµλ€ μƒμ„± ν† ν° μ
- `stream`: μ¤νΈλ¦¬λ° μ‘λ‹µ μ—¬λ¶€
- `frequency_penalty`: λ°λ³µ μ–µμ 
- `presence_penalty`: μƒλ΅μ΄ μ£Όμ  μ¥λ ¤

### 2. POST /v1/completions
ν…μ¤νΈ μ™„μ„± μƒμ„±

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "model": "deepseek-ai/DeepSeek-OCR",
  "prompt": "Once upon a time",
  "max_tokens": 100,
  "temperature": 0.7,
  "top_p": 1.0,
  "n": 1,
  "stream": false,
  "echo": false
}
```

**μ£Όμ” νλΌλ―Έν„°**:
- `prompt`: μ…λ ¥ ν”„λ΅¬ν”„νΈ (λ¬Έμμ—΄ λλ” ν† ν° λ°°μ—΄)
- `best_of`: μƒμ„±ν•  ν›„λ³΄ μ
- `echo`: ν”„λ΅¬ν”„νΈλ¥Ό μ‘λ‹µμ— ν¬ν•¨ν• μ§€ μ—¬λ¶€
- `logit_bias`: νΉμ • ν† ν°μ ν™•λ¥  μ΅°μ •

### 3. POST /v1/embeddings
ν…μ¤νΈ μ„λ² λ”© μƒμ„±

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "model": "deepseek-ai/DeepSeek-OCR",
  "input": ["ν…μ¤νΈ 1", "ν…μ¤νΈ 2"],
  "encoding_format": "float",
  "dimensions": 768,
  "add_special_tokens": true
}
```

**μ£Όμ” νλΌλ―Έν„°**:
- `input`: μ…λ ¥ ν…μ¤νΈ λ°°μ—΄ (λλ” ν† ν° λ°°μ—΄)
- `encoding_format`: `"float"` (κΈ°λ³Έκ°’)
- `dimensions`: μ¶λ ¥ μ„λ² λ”© μ°¨μ›
- `truncate_prompt_tokens`: ν”„λ΅¬ν”„νΈ ν† ν° μλ¥΄κΈ°

---

## π”Ά ν† ν°ν™” API

### POST /tokenize
ν…μ¤νΈλ¥Ό ν† ν°μΌλ΅ λ³€ν™

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "model": "deepseek-ai/DeepSeek-OCR",
  "prompt": "Hello, world!",
  "add_special_tokens": true,
  "return_token_strs": false
}
```

**νλΌλ―Έν„° μ„¤λ…**:
- `prompt`: μ…λ ¥ ν…μ¤νΈ
- `add_special_tokens`: νΉμ ν† ν° (BOS, EOS λ“±) μ¶”κ°€ μ—¬λ¶€
- `return_token_strs`: ν† ν° λ¬Έμμ—΄λ„ ν•¨κ» λ°ν™ν• μ§€ μ—¬λ¶€

### POST /detokenize
ν† ν°μ„ ν…μ¤νΈλ΅ λ³€ν™

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "model": "deepseek-ai/DeepSeek-OCR",
  "tokens": [123, 456, 789]
}
```

---

## π― λΉ„λ™κΈ° μ‘λ‹µ API

### POST /v1/responses
λΉ„λ™κΈ° μ‘λ‹µ μƒμ„± μ‘μ—… μ‹μ‘

**μ”μ²­ νλΌλ―Έν„°**:
```json
{
  "background": false,
  "include": ["code_interpreter_call.outputs"],
  "input": "string",
  "instructions": "string",
  "max_output_tokens": 0,
  "max_tool_calls": 0,
  "metadata": {},
  "model": "string",
  "modalities": ["text"],
  "response_format": {},
  "tools": []
}
```

### GET /v1/responses/{response_id}
νΉμ • μ‘λ‹µ μ‘μ—… μ΅°ν

### POST /v1/responses/{response_id}/cancel
νΉμ • μ‘λ‹µ μ‘μ—… μ·¨μ†

---

## π”„ μ¶”κ°€ κΈ°λ¥

### POST /pooling
ν’€λ§ μ‘μ—… μν–‰ (μ„λ² λ”© λ“±)

### POST /classify
λ¶„λ¥ μ‘μ—… μν–‰

---

## π¨ HTTP μ‘λ‹µ μ½”λ“

| μ½”λ“ | μ„¤λ… |
|------|------|
| `200` | μ„±κ³µ |
| `400` | μλ»λ μ”μ²­ (Bad Request) |
| `404` | λ¦¬μ†μ¤λ¥Ό μ°Ύμ„ μ μ—†μ (Not Found) |
| `422` | μ ν¨μ„± κ²€μ¦ μ¤λ¥ (Validation Error) |
| `500` | λ‚΄λ¶€ μ„λ²„ μ¤λ¥ (Internal Server Error) |
| `501` | κµ¬ν„λμ§€ μ•μ (Not Implemented) |

**μ—λ¬ μ‘λ‹µ ν•μ‹**:
```json
{
  "error": {
    "message": "μ¤λ¥ λ©”μ‹μ§€",
    "type": "μ¤λ¥ νƒ€μ…",
    "param": "λ¬Έμ κ°€ λ νλΌλ―Έν„°",
    "code": 0
  }
}
```

---

## π’΅ μ‚¬μ© μμ‹

### Python (OpenAI SDK μ‚¬μ©)
```python
from openai import OpenAI

client = OpenAI(
    api_key="EMPTY",
    base_url="http://10.10.10.200:19751/v1"
)

response = client.chat.completions.create(
    model="deepseek-ai/DeepSeek-OCR",
    messages=[
        {"role": "user", "content": "Hello!"}
    ]
)

print(response.choices[0].message.content)
```

### Python (LiteLLM μ‚¬μ©)
```python
import litellm

response = litellm.completion(
    model="openai/deepseek-ai/DeepSeek-OCR",
    messages=[{"role": "user", "content": "Hello!"}],
    api_base="http://10.10.10.200:19751/v1",
    api_key="EMPTY"
)

print(response.choices[0].message.content)
```

### cURL
```bash
curl -X POST "http://10.10.10.200:19751/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "deepseek-ai/DeepSeek-OCR",
    "messages": [
      {"role": "user", "content": "Hello!"}
    ],
    "temperature": 0.7,
    "max_tokens": 100
  }'
```

---

## π“ μ°Έκ³  μ‚¬ν•­

1. **OpenAI API νΈν™μ„±**: μ΄ APIλ” OpenAIμ API μ¤ν™κ³Ό κ±°μ λ™μΌν•κ² μ„¤κ³„λμ–΄ μμ–΄, OpenAI SDKλ¥Ό κ·Έλ€λ΅ μ‚¬μ©ν•  μ μμµλ‹λ‹¤.

2. **μ¤νΈλ¦¬λ° μ§€μ›**: `/v1/chat/completions`μ™€ `/v1/completions` μ—”λ“ν¬μΈνΈλ” Server-Sent Events (SSE)λ¥Ό ν†µν• μ¤νΈλ¦¬λ°μ„ μ§€μ›ν•©λ‹λ‹¤.

3. **λ¨λΈ νΉν™” κΈ°λ¥**: DeepSeek-OCR λ¨λΈμ€ OCR(κ΄‘ν•™ λ¬Έμ μΈμ‹)μ— νΉν™”λμ–΄ μμΌλ―€λ΅, μ΄λ―Έμ§€μ—μ„ ν…μ¤νΈλ¥Ό μ¶”μ¶ν•λ” μ‘μ—…μ— μµμ ν™”λμ–΄ μμµλ‹λ‹¤.

4. **μΈμ¦**: ν„μ¬ μ„¤μ •μ—μ„λ” API ν‚¤κ°€ ν•„μ”ν•μ§€ μ•κ±°λ‚ `"EMPTY"`λ΅ μ„¤μ •ν•  μ μμµλ‹λ‹¤.

---

## π”— κ΄€λ ¨ νμΌ

- **ν…μ¤νΈ μ¤ν¬λ¦½νΈ**: `test_vllm_litellm.py`
- **API λ¬Έμ„**: `swagger_api_docs.html`
- **Base URL**: `http://10.10.10.200:19751/v1`

